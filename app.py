import os
import openai
import streamlit as st
from dotenv import load_dotenv
import whisper
import tempfile
from diffusers import StableDiffusionPipeline

# ØªØ­Ù…ÙŠÙ„ Ù…ÙØ§ØªÙŠØ­ API
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.set_page_config(page_title="MNB AI Pro", layout="wide")
st.title("ğŸš€ MNB AI - Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ù€ OpenAI")

# Ø´Ø±ÙŠØ· Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
with st.sidebar:
    st.header("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª âš™ï¸")
    api_key = st.text_input("Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ OpenAI API", type="password")
    if api_key:
        openai.api_key = api_key

# ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù„Ù„ÙˆØ¸Ø§Ø¦Ù
tab1, tab2, tab3 = st.tabs(["ğŸ’¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø°ÙƒÙŠØ©", "ğŸ¨ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±", "ğŸ¤ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª"])

# ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¹ OpenAI
with tab1:
    st.subheader("Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    chat_input = st.text_area("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ...")
    
    if st.button("Ø¥Ø±Ø³Ø§Ù„", key="chat_btn"):
        if not openai.api_key:
            st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ API ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ")
        else:
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[{"role": "user", "content": chat_input}],
                temperature=0.7
            )
            st.success(response.choices[0].message.content)

# ØªØ¨ÙˆÙŠØ¨ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±
with tab2:
    st.subheader("ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    image_prompt = st.text_input("ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©")
    
    if st.button("ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©", key="image_btn"):
        pipe = StableDiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0")
        image = pipe(image_prompt).images[0]
        st.image(image, caption=image_prompt)

# ØªØ¨ÙˆÙŠØ¨ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª
with tab3:
    st.subheader("ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ")
    audio_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ", type=["mp3", "wav", "ogg"])
    
    if audio_file and st.button("ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ", key="audio_btn"):
        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            tmp.write(audio_file.read())
            model = whisper.load_model("base")
            result = model.transcribe(tmp.name)
            st.write("**Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù‚Ø±ÙˆØ¡:**")
            st.code(result["text"])

# Ù†Øµ ØªØ°ÙŠÙŠÙ„ÙŠ
st.markdown("---")
st.caption("MNB AI - Â© 2023 | ÙŠØ¯Ø¹Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù„ØºØ§Øª ÙˆØ§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")
